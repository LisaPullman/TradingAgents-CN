#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•é«˜æ€§èƒ½æ¨¡åž‹é…ç½®
éªŒè¯æ¯ä¸ªåˆ†æžå¸ˆæ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„ä¸“ç”¨é«˜æ€§èƒ½æ¨¡åž‹
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def test_default_config():
    """æµ‹è¯•é»˜è®¤é…ç½®æ˜¯å¦ä½¿ç”¨é«˜æ€§èƒ½æ¨¡åž‹"""
    print("ðŸ”§ æµ‹è¯•é»˜è®¤é…ç½®...")
    
    try:
        from tradingagents.default_config import DEFAULT_CONFIG
        
        print("ðŸ“Š é»˜è®¤é…ç½®æ£€æŸ¥:")
        print(f"  LLMæä¾›å•†: {DEFAULT_CONFIG['llm_provider']}")
        print(f"  æ·±åº¦æ€è€ƒæ¨¡åž‹: {DEFAULT_CONFIG['deep_think_llm']}")
        print(f"  å¿«é€Ÿæ€è€ƒæ¨¡åž‹: {DEFAULT_CONFIG['quick_think_llm']}")
        print(f"  å¸‚åœºåˆ†æžå¸ˆæ¨¡åž‹: {DEFAULT_CONFIG.get('market_analyst_llm', 'æœªé…ç½®')}")
        print(f"  åŸºæœ¬é¢åˆ†æžå¸ˆæ¨¡åž‹: {DEFAULT_CONFIG.get('fundamentals_analyst_llm', 'æœªé…ç½®')}")
        print(f"  æ–°é—»åˆ†æžå¸ˆæ¨¡åž‹: {DEFAULT_CONFIG.get('news_analyst_llm', 'æœªé…ç½®')}")
        print(f"  ç¤¾äº¤åª’ä½“åˆ†æžå¸ˆæ¨¡åž‹: {DEFAULT_CONFIG.get('social_analyst_llm', 'æœªé…ç½®')}")
        
        # éªŒè¯æ˜¯å¦ä½¿ç”¨é«˜æ€§èƒ½æ¨¡åž‹
        high_performance_models = [
            "Qwen/Qwen2.5-72B-Instruct",
            "meta-llama/Llama-3.1-70B-Instruct", 
            "deepseek-ai/DeepSeek-R1",
            "Qwen/Qwen2.5-32B-Instruct"
        ]
        
        checks = [
            ("æ·±åº¦æ€è€ƒæ¨¡åž‹", DEFAULT_CONFIG['deep_think_llm'] in high_performance_models),
            ("å¿«é€Ÿæ€è€ƒæ¨¡åž‹", DEFAULT_CONFIG['quick_think_llm'] in high_performance_models),
            ("å¸‚åœºåˆ†æžå¸ˆæ¨¡åž‹", DEFAULT_CONFIG.get('market_analyst_llm', '').replace('${MARKET_ANALYST_LLM:-', '').replace('}', '') in high_performance_models),
            ("åŸºæœ¬é¢åˆ†æžå¸ˆæ¨¡åž‹", DEFAULT_CONFIG.get('fundamentals_analyst_llm', '').replace('${FUNDAMENTALS_ANALYST_LLM:-', '').replace('}', '') in high_performance_models),
            ("æ–°é—»åˆ†æžå¸ˆæ¨¡åž‹", DEFAULT_CONFIG.get('news_analyst_llm', '').replace('${NEWS_ANALYST_LLM:-', '').replace('}', '') in high_performance_models),
            ("ç¤¾äº¤åª’ä½“åˆ†æžå¸ˆæ¨¡åž‹", DEFAULT_CONFIG.get('social_analyst_llm', '').replace('${SOCIAL_ANALYST_LLM:-', '').replace('}', '') in high_performance_models),
        ]
        
        all_passed = True
        for check_name, passed in checks:
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {check_name}")
            if not passed:
                all_passed = False
        
        return all_passed
        
    except Exception as e:
        print(f"âŒ é»˜è®¤é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_env_example():
    """æµ‹è¯•.env.exampleæ–‡ä»¶æ˜¯å¦åŒ…å«é«˜æ€§èƒ½æ¨¡åž‹é…ç½®"""
    print("\nðŸ“„ æµ‹è¯•.env.exampleé…ç½®...")
    
    try:
        env_file = project_root / ".env.example"
        content = env_file.read_text(encoding='utf-8')
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸“ç”¨åˆ†æžå¸ˆæ¨¡åž‹é…ç½®
        required_configs = [
            "MARKET_ANALYST_LLM=",
            "FUNDAMENTALS_ANALYST_LLM=",
            "NEWS_ANALYST_LLM=",
            "SOCIAL_ANALYST_LLM=",
            "DEEP_THINK_LLM=",
            "QUICK_THINK_LLM=",
            "SILICONFLOW_API_KEY="
        ]
        
        # æ£€æŸ¥é«˜æ€§èƒ½æ¨¡åž‹
        high_performance_models = [
            "Qwen/Qwen2.5-72B-Instruct",
            "meta-llama/Llama-3.1-70B-Instruct",
            "deepseek-ai/DeepSeek-R1",
            "Qwen/Qwen2.5-32B-Instruct"
        ]
        
        print("ðŸ“‹ .env.exampleæ£€æŸ¥:")
        
        all_passed = True
        for config in required_configs:
            if config in content:
                print(f"  âœ… åŒ…å«é…ç½®: {config}")
            else:
                print(f"  âŒ ç¼ºå°‘é…ç½®: {config}")
                all_passed = False
        
        for model in high_performance_models:
            if model in content:
                print(f"  âœ… åŒ…å«é«˜æ€§èƒ½æ¨¡åž‹: {model}")
            else:
                print(f"  âš ï¸ æœªæ‰¾åˆ°æ¨¡åž‹: {model}")
        
        return all_passed
        
    except Exception as e:
        print(f"âŒ .env.exampleæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_specialized_llm_creation():
    """æµ‹è¯•ä¸“ç”¨LLMåˆ›å»ºåŠŸèƒ½"""
    print("\nðŸ¤– æµ‹è¯•ä¸“ç”¨LLMåˆ›å»º...")
    
    try:
        from tradingagents.graph.setup import GraphSetup
        from tradingagents.default_config import DEFAULT_CONFIG
        
        # æ¨¡æ‹Ÿé…ç½®
        config = DEFAULT_CONFIG.copy()
        config["market_analyst_llm"] = "meta-llama/Llama-3.1-70B-Instruct"
        config["fundamentals_analyst_llm"] = "Qwen/Qwen2.5-72B-Instruct"
        
        # åˆ›å»ºGraphSetupå®žä¾‹ï¼ˆéœ€è¦æ¨¡æ‹Ÿå…¶ä»–å‚æ•°ï¼‰
        setup = GraphSetup(
            quick_thinking_llm=None,  # æ¨¡æ‹Ÿ
            deep_thinking_llm=None,   # æ¨¡æ‹Ÿ
            toolkit=None,             # æ¨¡æ‹Ÿ
            tool_nodes={},            # æ¨¡æ‹Ÿ
            bull_memory=None,         # æ¨¡æ‹Ÿ
            bear_memory=None,         # æ¨¡æ‹Ÿ
            trader_memory=None,       # æ¨¡æ‹Ÿ
            invest_judge_memory=None, # æ¨¡æ‹Ÿ
            risk_manager_memory=None, # æ¨¡æ‹Ÿ
            conditional_logic=None,   # æ¨¡æ‹Ÿ
            config=config
        )
        
        print("ðŸ“Š ä¸“ç”¨LLMåˆ›å»ºæµ‹è¯•:")
        
        # æµ‹è¯•_create_specialized_llmæ–¹æ³•æ˜¯å¦å­˜åœ¨
        if hasattr(setup, '_create_specialized_llm'):
            print("  âœ… _create_specialized_llmæ–¹æ³•å­˜åœ¨")
            
            # æµ‹è¯•æ–¹æ³•è°ƒç”¨ï¼ˆåœ¨æ²¡æœ‰APIå¯†é’¥çš„æƒ…å†µä¸‹ä¼šå›žé€€ï¼‰
            try:
                result = setup._create_specialized_llm("market_analyst_llm")
                print("  âœ… æ–¹æ³•è°ƒç”¨æˆåŠŸ")
                return True
            except Exception as e:
                print(f"  âš ï¸ æ–¹æ³•è°ƒç”¨å¤±è´¥ï¼ˆé¢„æœŸï¼Œå› ä¸ºç¼ºå°‘APIå¯†é’¥ï¼‰: {e}")
                return True  # è¿™æ˜¯é¢„æœŸçš„
        else:
            print("  âŒ _create_specialized_llmæ–¹æ³•ä¸å­˜åœ¨")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸“ç”¨LLMåˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_cli_options():
    """æµ‹è¯•CLIé€‰é¡¹æ˜¯å¦ä¼˜å…ˆæ˜¾ç¤ºé«˜æ€§èƒ½æ¨¡åž‹"""
    print("\nðŸ’» æµ‹è¯•CLIé€‰é¡¹...")
    
    try:
        from cli.utils import select_shallow_thinking_agent, select_deep_thinking_agent
        
        # æ£€æŸ¥CLIé€‰é¡¹æ˜¯å¦å­˜åœ¨
        print("ðŸ“‹ CLIé€‰é¡¹æ£€æŸ¥:")
        print("  âœ… select_shallow_thinking_agentå‡½æ•°å­˜åœ¨")
        print("  âœ… select_deep_thinking_agentå‡½æ•°å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é«˜æ€§èƒ½æ¨¡åž‹é€‰é¡¹
        # è¿™é‡Œæˆ‘ä»¬ä¸èƒ½ç›´æŽ¥è°ƒç”¨å‡½æ•°ï¼ˆå› ä¸ºå®ƒä»¬éœ€è¦ç”¨æˆ·äº¤äº’ï¼‰ï¼Œ
        # ä½†å¯ä»¥æ£€æŸ¥æºä»£ç ä¸­æ˜¯å¦åŒ…å«é«˜æ€§èƒ½æ¨¡åž‹
        cli_file = project_root / "cli" / "utils.py"
        content = cli_file.read_text(encoding='utf-8')
        
        high_performance_indicators = [
            "ðŸ¥‡æœ€é«˜æ€§èƒ½",
            "ðŸ¥ˆè¶…å¼ºæ€§èƒ½", 
            "ðŸ¥‰æŽ¨ç†ä¸“ç”¨",
            "Qwen/Qwen2.5-72B-Instruct",
            "meta-llama/Llama-3.1-70B-Instruct"
        ]
        
        found_indicators = []
        for indicator in high_performance_indicators:
            if indicator in content:
                found_indicators.append(indicator)
        
        if len(found_indicators) >= 3:
            print(f"  âœ… CLIåŒ…å«é«˜æ€§èƒ½æ¨¡åž‹æŒ‡ç¤ºå™¨: {len(found_indicators)}/5")
            return True
        else:
            print(f"  âŒ CLIç¼ºå°‘é«˜æ€§èƒ½æ¨¡åž‹æŒ‡ç¤ºå™¨: {len(found_indicators)}/5")
            return False
            
    except Exception as e:
        print(f"âŒ CLIé€‰é¡¹æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_performance_ranking():
    """æµ‹è¯•æ¨¡åž‹æ€§èƒ½æŽ’åº"""
    print("\nðŸ† æµ‹è¯•æ¨¡åž‹æ€§èƒ½æŽ’åº...")
    
    # å®šä¹‰æ€§èƒ½æŽ’åºï¼ˆä»Žé«˜åˆ°ä½Žï¼‰
    performance_ranking = [
        "Qwen/Qwen2.5-72B-Instruct",      # ðŸ¥‡ 72Bå‚æ•°ï¼Œæœ€é«˜æ€§èƒ½
        "meta-llama/Llama-3.1-70B-Instruct", # ðŸ¥ˆ 70Bå‚æ•°ï¼Œé•¿ä¸Šä¸‹æ–‡
        "deepseek-ai/DeepSeek-R1",         # ðŸ¥‰ æŽ¨ç†ä¸“ç”¨
        "deepseek-ai/DeepSeek-V3",         # ðŸ… æœ€æ–°ç‰ˆæœ¬
        "Qwen/Qwen2.5-32B-Instruct",      # ðŸŽ¯ ä¸­æ–‡ä¼˜åŒ–
        "Qwen/Qwen2.5-14B-Instruct",      # âš¡ è½»é‡çº§
    ]
    
    # å®šä¹‰åˆ†æžå¸ˆä¸“ä¸šåŒ–åˆ†é…
    analyst_assignments = {
        "åŸºæœ¬é¢åˆ†æžå¸ˆ": "Qwen/Qwen2.5-72B-Instruct",      # éœ€è¦æœ€å¼ºè®¡ç®—èƒ½åŠ›
        "å¸‚åœºåˆ†æžå¸ˆ": "meta-llama/Llama-3.1-70B-Instruct",   # éœ€è¦é•¿ä¸Šä¸‹æ–‡å¤„ç†
        "æ–°é—»åˆ†æžå¸ˆ": "deepseek-ai/DeepSeek-R1",            # éœ€è¦å¼ºæŽ¨ç†èƒ½åŠ›
        "ç¤¾äº¤åª’ä½“åˆ†æžå¸ˆ": "Qwen/Qwen2.5-32B-Instruct",      # éœ€è¦ä¸­æ–‡ä¼˜åŒ–
    }
    
    print("ðŸ“Š æ¨¡åž‹æ€§èƒ½æŽ’åºï¼ˆä»Žé«˜åˆ°ä½Žï¼‰:")
    for i, model in enumerate(performance_ranking, 1):
        print(f"  {i}. {model}")
    
    print("\nðŸŽ¯ åˆ†æžå¸ˆä¸“ä¸šåŒ–åˆ†é…:")
    for analyst, model in analyst_assignments.items():
        rank = performance_ranking.index(model) + 1
        print(f"  {analyst}: {model} (æ€§èƒ½æŽ’å: #{rank})")
    
    # éªŒè¯åˆ†é…æ˜¯å¦åˆç†ï¼ˆåŸºæœ¬é¢åˆ†æžå¸ˆåº”è¯¥ä½¿ç”¨æœ€é«˜æ€§èƒ½æ¨¡åž‹ï¼‰
    fundamentals_model = analyst_assignments["åŸºæœ¬é¢åˆ†æžå¸ˆ"]
    if fundamentals_model == performance_ranking[0]:
        print("  âœ… åŸºæœ¬é¢åˆ†æžå¸ˆä½¿ç”¨æœ€é«˜æ€§èƒ½æ¨¡åž‹")
        return True
    else:
        print("  âŒ åŸºæœ¬é¢åˆ†æžå¸ˆæœªä½¿ç”¨æœ€é«˜æ€§èƒ½æ¨¡åž‹")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ðŸš€ é«˜æ€§èƒ½æ¨¡åž‹é…ç½®æµ‹è¯•")
    print("=" * 60)
    print("ç›®æ ‡: éªŒè¯æ¯ä¸ªåˆ†æžå¸ˆéƒ½ä½¿ç”¨ä»·æ ¼æœ€è´µã€æ€§èƒ½æœ€å¥½çš„ä¸“ç”¨æ¨¡åž‹")
    print("=" * 60)
    
    tests = [
        ("é»˜è®¤é…ç½®æ£€æŸ¥", test_default_config),
        (".env.exampleé…ç½®", test_env_example),
        ("ä¸“ç”¨LLMåˆ›å»º", test_specialized_llm_creation),
        ("CLIé€‰é¡¹æ£€æŸ¥", test_cli_options),
        ("æ¨¡åž‹æ€§èƒ½æŽ’åº", test_model_performance_ranking),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} å‡ºçŽ°å¼‚å¸¸: {e}")
            results[test_name] = False
    
    # æ€»ç»“ç»“æžœ
    print("\nðŸ“Š æµ‹è¯•ç»“æžœæ€»ç»“")
    print("=" * 60)
    
    passed = 0
    total = len(tests)
    
    for test_name, success in results.items():
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if success:
            passed += 1
    
    print(f"\nðŸŽ¯ æ€»ä½“ç»“æžœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nðŸŽ‰ é«˜æ€§èƒ½æ¨¡åž‹é…ç½®æˆåŠŸï¼")
        print("ðŸ’¡ çŽ°åœ¨ç³»ç»Ÿå°†ï¼š")
        print("  - åŸºæœ¬é¢åˆ†æžå¸ˆä½¿ç”¨ Qwen 2.5 72B (æœ€é«˜æ€§èƒ½)")
        print("  - å¸‚åœºåˆ†æžå¸ˆä½¿ç”¨ Llama 3.1 70B (é•¿ä¸Šä¸‹æ–‡)")
        print("  - æ–°é—»åˆ†æžå¸ˆä½¿ç”¨ DeepSeek R1 (æŽ¨ç†ä¸“ç”¨)")
        print("  - ç¤¾äº¤åª’ä½“åˆ†æžå¸ˆä½¿ç”¨ Qwen 2.5 32B (ä¸­æ–‡ä¼˜åŒ–)")
        print("  - æ·±åº¦æ€è€ƒä½¿ç”¨ Qwen 2.5 72B (æœ€å¼ºå†³ç­–)")
        print("  - å¿«é€Ÿæ€è€ƒä½¿ç”¨ DeepSeek R1 (å¿«é€ŸæŽ¨ç†)")
    elif passed >= total * 0.8:
        print("\nâœ… é«˜æ€§èƒ½æ¨¡åž‹é…ç½®åŸºæœ¬æˆåŠŸï¼")
        print("âš ï¸ éƒ¨åˆ†åŠŸèƒ½å¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print("\nâŒ é«˜æ€§èƒ½æ¨¡åž‹é…ç½®ä¸å®Œæ•´")
        print("ðŸ”§ éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥å’Œä¿®å¤")
    
    return passed >= total * 0.8


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
